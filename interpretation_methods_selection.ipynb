{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a743b1d-4458-4c5e-9ffc-d82c6b66f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import load\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from src.Sparse_vector.sparse_vector import SparseVector\n",
    "from src.data_preparation import get_train_test_dataset\n",
    "from src.train_test import set_random_seed, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1891dabf-3a98-407b-8822-06b2eb494b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f\"z_dna/hg38_dna/\") if f\"{chrom}_\" in i])\n",
    "    return \"\".join([load(f\"z_dna/hg38_dna/{file}\") for file in files])\n",
    "\n",
    "\n",
    "chroms = [f\"chr{i}\" for i in list(range(1, 23)) + [\"X\", \"Y\", \"M\"]]\n",
    "all_features = [\n",
    "    i[:-4] for i in os.listdir(\"z_dna/hg38_features/sparse/\") if i.endswith(\".pkl\")\n",
    "]\n",
    "groups = [\"DNase-seq\", \"Histone\", \"RNA polymerase\", \"TFs and others\"]\n",
    "feature_names = [i for i in all_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5aca43e-221e-447d-ba72-928d9fe14796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf77d6e9d29949d59588093cbbce46ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b101de5ec67418f8f712a8343c3b2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 6.03 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chroms)}\n",
    "\n",
    "ZDNA_data = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873352f8-1cbe-442a-a3a7-c536dfcc23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2489564/2489564 [00:28<00:00, 88825.31it/s] \n",
      "100%|██████████| 2421935/2421935 [00:26<00:00, 93090.79it/s] \n",
      "100%|██████████| 1982955/1982955 [00:21<00:00, 94006.96it/s] \n",
      "100%|██████████| 1902145/1902145 [00:20<00:00, 92947.13it/s] \n",
      "100%|██████████| 1815382/1815382 [00:19<00:00, 92066.47it/s] \n",
      "100%|██████████| 1708059/1708059 [00:17<00:00, 98563.90it/s] \n",
      "100%|██████████| 1593459/1593459 [00:17<00:00, 89336.54it/s] \n",
      "100%|██████████| 1451386/1451386 [00:14<00:00, 97134.63it/s] \n",
      "100%|██████████| 1383947/1383947 [00:16<00:00, 86148.48it/s] \n",
      "100%|██████████| 1337974/1337974 [00:13<00:00, 98076.71it/s] \n",
      "100%|██████████| 1350866/1350866 [00:13<00:00, 98410.23it/s] \n",
      "100%|██████████| 1332753/1332753 [00:16<00:00, 82801.21it/s] \n",
      "100%|██████████| 1143643/1143643 [00:11<00:00, 97476.80it/s] \n",
      "100%|██████████| 1070437/1070437 [00:11<00:00, 96024.21it/s]\n",
      "100%|██████████| 1019911/1019911 [00:10<00:00, 100163.54it/s]\n",
      "100%|██████████| 903383/903383 [00:09<00:00, 96513.35it/s] \n",
      "100%|██████████| 832574/832574 [00:08<00:00, 95807.56it/s] \n",
      "100%|██████████| 803732/803732 [00:10<00:00, 73294.31it/s] \n",
      "100%|██████████| 586176/586176 [00:06<00:00, 97127.36it/s] \n",
      "100%|██████████| 644441/644441 [00:06<00:00, 98579.11it/s] \n",
      "100%|██████████| 467099/467099 [00:04<00:00, 95694.49it/s] \n",
      "100%|██████████| 508184/508184 [00:05<00:00, 96876.42it/s] \n",
      "100%|██████████| 1560408/1560408 [00:16<00:00, 97239.00it/s] \n",
      "100%|██████████| 572274/572274 [00:05<00:00, 97332.92it/s] \n",
      "100%|██████████| 165/165 [00:00<00:00, 82990.79it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "width = 100\n",
    "\n",
    "train_dataset, test_dataset = get_train_test_dataset(\n",
    "    width, chroms, feature_names, DNA, DNA_features, ZDNA_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1446acb-a291-4940-be4c-6a8da81282a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"batch_size\": 1, \"num_workers\": 5, \"shuffle\": True, \"pin_memory\": True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81ba996-e8aa-4166-b06a-bb703e279304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score, average_precision_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class ImageZ(nn.Module):\n",
    "    def __init__(self, width, features_count):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.features_count = features_count\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(2, 4),\n",
    "            nn.Conv2d(4, 8, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 8),\n",
    "            nn.Conv2d(8, 16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, 16),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 64),\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 5), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(32, 128),\n",
    "            nn.Conv2d(128, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(32, 64),\n",
    "            nn.Conv2d(64, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 32),\n",
    "            nn.Conv2d(32, 16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, 16),\n",
    "            nn.Conv2d(16, 8, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 8),\n",
    "            nn.Conv2d(8, 4, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 4),\n",
    "            nn.Conv2d(4, 1, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(1, 1),\n",
    "            nn.AlphaDropout(p=0.2),\n",
    "            nn.Linear(features_count + 4, 500),\n",
    "            nn.AlphaDropout(p=0.2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(500, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.reshape(batch, 1, self.width, self.features_count + 4)\n",
    "        x = self.seq(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437ab0dc-0b06-4818-a229-351bac4f53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model = ImageZ(width, len(feature_names))\n",
    "model.load_state_dict(torch.load(\"couzine_0.897250.pt\", weights_only=True))\n",
    "model = model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80b44f7-d8a2-4b89-8378-7d71a0929c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.metrics import infidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14693496-4212-43af-8567-ad0a8adaee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    IntegratedGradients,\n",
    "    GradientShap,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    Saliency,\n",
    "    InputXGradient,\n",
    "    GuidedBackprop,\n",
    "    Deconvolution,\n",
    "    GuidedGradCam,\n",
    "    FeatureAblation,\n",
    "    FeaturePermutation,\n",
    "    Occlusion,\n",
    "    ShapleyValueSampling,\n",
    "    Lime,\n",
    "    KernelShap,\n",
    ")\n",
    "\n",
    "ATTR_METHODS = {\n",
    "    IntegratedGradients:    \"IntegratedGradients\",\n",
    "    GradientShap:           \"GradientShap\",\n",
    "    DeepLift:               \"DeepLift\",\n",
    "    Saliency:               \"Saliency\",\n",
    "    InputXGradient:         \"InputXGradient\",\n",
    "    GuidedBackprop:         \"GuidedBackpropagation\",\n",
    "    Deconvolution:          \"Deconvolution\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f6a216-ed27-468c-aaea-b2ba2c58c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.metrics import infidelity\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import statistics\n",
    "\n",
    "\n",
    "def perturb_fn(inputs):\n",
    "    noise = torch.tensor(np.random.normal(0, 0.001, inputs.shape)).float().to(device)\n",
    "    noise_inputs = inputs - noise\n",
    "    return noise, noise_inputs.to(device)\n",
    "\n",
    "\n",
    "def get_infidelity(method, n_perturb_samples=10, normalize=False):\n",
    "\n",
    "    subset_size = 10000\n",
    "    indices = list(range(subset_size))\n",
    "\n",
    "    subset = Subset(test_dataset, indices)\n",
    "    params = {\"batch_size\": 1, \"num_workers\": 5, \"shuffle\": True, \"pin_memory\": True}\n",
    "\n",
    "    loader_test_mini = data.DataLoader(subset, **params)\n",
    "\n",
    "    infid_list = []\n",
    "    for x, y_true in tqdm(loader_test_mini):\n",
    "        x, y_true = x.to(device), y_true.to(device).long()\n",
    "        explain = method(model)\n",
    "        if ATTR_METHODS[method] == \"IntegratedGradients\":\n",
    "            attribution = explain.attribute(x, target=1, n_steps=1)\n",
    "            now_list = []\n",
    "            for _ in range(n_perturb_samples):\n",
    "                infid = infidelity(\n",
    "                    model,\n",
    "                    perturb_fn,\n",
    "                    x,\n",
    "                    attribution,\n",
    "                    n_perturb_samples=1,\n",
    "                    normalize=normalize,\n",
    "                )\n",
    "                now_list.append(infid.item())\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            infid_list.append(statistics.mean(now_list))\n",
    "        elif ATTR_METHODS[method] == \"DeepLift\":\n",
    "            now_list = []\n",
    "            for _ in range(n_perturb_samples):\n",
    "                index_list = []\n",
    "                for index in random.sample(range(x.shape[1]), k=5):\n",
    "                    attribution = explain.attribute(x.to(device), target=(index, 1))\n",
    "                    infid = infidelity(\n",
    "                        model,\n",
    "                        perturb_fn,\n",
    "                        x,\n",
    "                        attribution,\n",
    "                        n_perturb_samples=1,\n",
    "                        normalize=normalize,\n",
    "                    )\n",
    "                    index_list.append(infid.item())\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                now_list.append(statistics.mean(index_list))\n",
    "            infid_list.append(statistics.mean(now_list))\n",
    "        elif ATTR_METHODS[method] == \"GradientShap\":\n",
    "            now_list = []\n",
    "            for _ in range(n_perturb_samples):\n",
    "                index_list = []\n",
    "                for index in random.sample(range(x.shape[1]), k=5):\n",
    "                    attribution = explain.attribute(\n",
    "                        x.to(device), target=(index, 1), baselines=torch.zeros_like(x)\n",
    "                    )\n",
    "                    infid = infidelity(\n",
    "                        model,\n",
    "                        perturb_fn,\n",
    "                        x,\n",
    "                        attribution,\n",
    "                        n_perturb_samples=1,\n",
    "                        normalize=normalize,\n",
    "                    )\n",
    "                    index_list.append(infid.item())\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                now_list.append(statistics.mean(index_list))\n",
    "            infid_list.append(statistics.mean(now_list))\n",
    "\n",
    "        else:\n",
    "            attribution = explain.attribute(x, target=1)\n",
    "            now_list = []\n",
    "            for _ in range(n_perturb_samples):\n",
    "                infid = infidelity(\n",
    "                    model,\n",
    "                    perturb_fn,\n",
    "                    x,\n",
    "                    attribution,\n",
    "                    n_perturb_samples=1,\n",
    "                    normalize=normalize,\n",
    "                )\n",
    "                now_list.append(infid.item())\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            infid_list.append(statistics.mean(now_list))\n",
    "\n",
    "    return statistics.mean(infid_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d070ee66-9734-436f-ac2d-06f9445ed3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for method in tqdm(ATTR_METHODS.keys()):\n",
    "    inf_value = get_infidelity(method, 4, True)\n",
    "    answer.append({ATTR_METHODS[method]: inf_value})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google Colab Analog 2024 (PyTorch 2.5.1 + TensorFlow 2.18) [python-google_colab_gpu_2024]",
   "language": "python",
   "name": "conda-env-python-google_colab_gpu_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
